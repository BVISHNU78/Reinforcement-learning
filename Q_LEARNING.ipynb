{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q LEARNING.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ_p7vvxg6td"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "rewards=np.array([\n",
        "[-1,-1,-1,-1,-1,0,-1],\n",
        "[-1,-1,-1,-1,0,-1,-1],\n",
        "[-1,-1,-1,0,-1,-1,100],\n",
        "[0,-1,-1,0,-1,-1,-1],\n",
        "[-1,0,-1,0,-1,0,-1],\n",
        "[0,0,0,0,-1,-1,-1],\n",
        "[-1,0,-1,0,-1,-1,0]                \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ98OGEpi7HK"
      },
      "source": [
        "pd.DataFrame(rewards)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBEpqKwVkOHk"
      },
      "source": [
        "def initialize_q(n,m):\n",
        "  return np.zeros((n,m))\n",
        "q_matrix=initialize_q(7,7)\n",
        "pd.DataFrame(q_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sybxt7r47jov"
      },
      "source": [
        "def take_action(current_state,reward_matrix,gamma,verbose=False):\n",
        "  action=get_action(current_state,reward_matrix)\n",
        "  sa_reward=reward_matrix[current_state,action]\n",
        "  ns_reward=max(q_matrix[action,])\n",
        "  q_current_state=sa_reward+(gamma*ns_reward)\n",
        "  q_matrix[current_state,action]=q_current_state\n",
        "  new_state=action\n",
        "  if verbose:\n",
        "    print(q_matrix)\n",
        "    print(f\"Old_State: {current_state} | New_State:{new_state}\\n\\n\")\n",
        "    if new_state == 5:\n",
        "     print(f\"Agent has reached its goal!\")\n",
        "  return new_state\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6ILAV52pEpm"
      },
      "source": [
        "def set_initial_state(rooms=7):\n",
        "  return np.random.randint(0,rooms)\n",
        "def get_action(current_state,reward_matrix):\n",
        "  valid_actions=[]\n",
        "  for action in enumerate(reward_matrix[current_state]):\n",
        "    if action[1]!=-1:\n",
        "      valid_actions +=[action[0]]\n",
        "  return random.choice(valid_actions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcNzVXP4xcfj"
      },
      "source": [
        "def intialize_episode(reward_matrix,initial_state,gamma,verbose=False):\n",
        "  current_state=initial_state\n",
        "  while True:\n",
        "    current_state=take_action(current_state,reward_matrix,gamma,verbose)\n",
        "    if current_state==5:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77zIohyuKy85"
      },
      "source": [
        "def train_agent(iterations,reward_matrix,gamma,verbose = False):\n",
        "  print(\"Training in progress\")\n",
        "  for episode in range(iterations):\n",
        "    initial_state = set_initial_state()\n",
        "    intialize_episode(reward_matrix,initial_state,gamma,verbose)\n",
        "  print(\"Training complete\")\n",
        "\n",
        "  return q_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB8_KimE11bN"
      },
      "source": [
        "def normalize_matrix(q_matrix):\n",
        "     normalized_q = q_matrix/max(q_matrix[q_matrix.nonzero()])*100\n",
        "     return normalized_q.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxOpGoi0Yaip"
      },
      "source": [
        "gamma =0.1\n",
        "initial_state=set_initial_state()\n",
        "initial_action=get_action(initial_state,rewards)\n",
        "intialize_episode(rewards,initial_state,gamma,True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA-vsU_uVX3P"
      },
      "source": [
        "gamma=0.8\n",
        "initial_state=set_initial_state()\n",
        "initial_action=get_action(initial_state,rewards)\n",
        "q_table = train_agent(2000,rewards,gamma,False)\n",
        "pd.DataFrame(q_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKyXLwEiV1Sy"
      },
      "source": [
        "pd.DataFrame(normalize_matrix(q_table))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVRMN7dWL9b"
      },
      "source": [
        "def deploy_agent(init_state,q_table):\n",
        "  print(\"Start:\",init_state)\n",
        "  state=init_state\n",
        "  steps=0\n",
        "  while True:\n",
        "    steps +=1\n",
        "    action =np.argmax(q_table[state,:])\n",
        "    print(action)\n",
        "    state=action\n",
        "    if action ==5:\n",
        "      print(\"Finished!\")\n",
        "      return steps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2gPSg6sJsLJ"
      },
      "source": [
        "start_room=1\n",
        "steps=deploy_agent(start_room,q_table)\n",
        "print(\"Number of Rooms/actions:\",steps)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}